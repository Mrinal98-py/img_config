pip install torch torchvision numpy matplotlib

##--

import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import transforms
from PIL import Image
import numpy as np
import matplotlib.pyplot as plt

# Define the neural network architecture
class DIPNet(nn.Module):
    def __init__(self):
        super(DIPNet, self).__init__()
        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1)
        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)
        self.conv3 = nn.Conv2d(128, 64, kernel_size=3, stride=1, padding=1)
        self.conv4 = nn.Conv2d(64, 3, kernel_size=3, stride=1, padding=1)

    def forward(self, x):
        x = torch.relu(self.conv1(x))
        x = torch.relu(self.conv2(x))
        x = torch.relu(self.conv3(x))
        x = torch.sigmoid(self.conv4(x))
        return x

# Function to load and preprocess the image
def load_image(image_path):
    image = Image.open(image_path).convert('RGB')
    transform = transforms.Compose([
        transforms.Resize((256, 256)),
        transforms.ToTensor()
    ])
    image = transform(image).unsqueeze(0)
    return image

# Function to display the image
def show_image(tensor_image):
    image = tensor_image.squeeze().permute(1, 2, 0).detach().cpu().numpy()
    plt.imshow(image)
    plt.show()

# Load the broken image
broken_image_path = 'path_to_broken_image.png'
broken_image = load_image(broken_image_path)

# Initialize the neural network and optimizer
net = DIPNet().to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))
optimizer = optim.Adam(net.parameters(), lr=0.01)

# Train the network to inpaint the image
for epoch in range(1000):
    optimizer.zero_grad()
    output = net(torch.randn_like(broken_image).to(torch.device('cuda' if torch.cuda.is_available() else 'cpu')))
    loss = nn.MSELoss()(output, broken_image)
    loss.backward()
    optimizer.step()
    
    if (epoch + 1) % 100 == 0:
        print(f"Epoch [{epoch + 1}/1000], Loss: {loss.item():.4f}")

# Show the fixed image
show_image(output)

##--

import cv2
import numpy as np

# Load the broken image
broken_image_path = 'path_to_broken_image.png'
broken_image = cv2.imread(broken_image_path)

# Perform inpainting using the PatchMatch algorithm
mask = cv2.cvtColor(broken_image, cv2.COLOR_BGR2GRAY)
mask[mask != 255] = 1
mask[mask == 255] = 0

fixed_image = cv2.inpaint(broken_image, mask, inpaintRadius=3, flags=cv2.INPAINT_TELEA)

# Save and display the fixed image
fixed_image_path = 'path_to_fixed_image.png'
cv2.imwrite(fixed_image_path, fixed_image)
cv2.imshow('Fixed Image', fixed_image)
cv2.waitKey(0)
cv2.destroyAllWindows()

##--

pip install tensorflow numpy opencv-python

##--

import tensorflow as tf
from tensorflow.keras import layers, models

def contextual_attention_model(input_shape=(256, 256, 3)):
    inputs = tf.keras.Input(input_shape)

    # Encoder
    conv1 = layers.Conv2D(64, kernel_size=4, strides=2, padding='same')(inputs)
    conv1 = layers.LeakyReLU(alpha=0.2)(conv1)

    conv2 = layers.Conv2D(128, kernel_size=4, strides=2, padding='same')(conv1)
    conv2 = layers.BatchNormalization()(conv2)
    conv2 = layers.LeakyReLU(alpha=0.2)(conv2)

    conv3 = layers.Conv2D(256, kernel_size=4, strides=2, padding='same')(conv2)
    conv3 = layers.BatchNormalization()(conv3)
    conv3 = layers.LeakyReLU(alpha=0.2)(conv3)

    # Contextual Attention Layer (simplified)
    attention = layers.Conv2D(256, kernel_size=3, padding='same', activation='relu')(conv3)

    # Decoder
    deconv1 = layers.Conv2DTranspose(128, kernel_size=4, strides=2, padding='same')(attention)
    deconv1 = layers.BatchNormalization()(deconv1)
    deconv1 = layers.ReLU()(deconv1)

    deconv2 = layers.Conv2DTranspose(64, kernel_size=4, strides=2, padding='same')(deconv1)
    deconv2 = layers.BatchNormalization()(deconv2)
    deconv2 = layers.ReLU()(deconv2)

    deconv3 = layers.Conv2DTranspose(3, kernel_size=4, strides=2, padding='same')(deconv2)
    outputs = layers.Activation('sigmoid')(deconv3)

    return models.Model(inputs, outputs)

# Define the model
model = contextual_attention_model()
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Example usage with a dummy dataset
# Note: For real usage, replace this with actual data loading and preprocessing
import numpy as np

# Dummy dataset
X_train = np.random.rand(100, 256, 256, 3)
y_train = np.random.rand(100, 256, 256, 3)

# Train the model
model.fit(X_train, y_train, epochs=50, batch_size=8)

# Use the trained model to fix broken images
def fix_broken_image(model, image_path, output_path):
    image = cv2.imread(image_path)
    image_resized = cv2.resize(image, (256, 256))
    image_normalized = image_resized / 255.0
    image_input = np.expand_dims(image_normalized, axis=0)

    fixed_image = model.predict(image_input)[0]
    fixed_image = (fixed_image * 255).astype(np.uint8)
    fixed_image_resized = cv2.resize(fixed_image, (image.shape[1], image.shape[0]))

    cv2.imwrite(output_path, fixed_image_resized)
    cv2.imshow('Fixed Image', fixed_image_resized)
    cv2.waitKey(0)
    cv2.destroyAllWindows()

# Path to the broken image
broken_image_path = 'path_to_broken_image.png'
output_image_path = 'path_to_fixed_image.png'

# Fix the broken image
fix_broken_image(model, broken_image_path, output_image_path)

##--

