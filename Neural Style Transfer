pip install tensorflow numpy opencv-python

##--

import tensorflow as tf
from tensorflow.keras.applications import VGG19
from tensorflow.keras.models import Model
from tensorflow.keras.preprocessing import image as kp_image
from tensorflow.keras import backend as K
import numpy as np
import cv2

def load_and_process_img(img_path):
    img = kp_image.load_img(img_path, target_size=(256, 256))
    img = kp_image.img_to_array(img)
    img = np.expand_dims(img, axis=0)
    img = tf.keras.applications.vgg19.preprocess_input(img)
    return img

def deprocess_img(processed_img):
    x = processed_img.copy()
    if len(x.shape) == 4:
        x = np.squeeze(x, 0)
    assert len(x.shape) == 3
    if x.shape[2] == 4:
        x = x[:, :, :3]
    x[:, :, 0] += 103.939
    x[:, :, 1] += 116.779
    x[:, :, 2] += 123.68
    x = x[:, :, ::-1]
    x = np.clip(x, 0, 255).astype('uint8')
    return x

def get_model():
    vgg = VGG19(include_top=False, weights='imagenet')
    vgg.trainable = False
    content_layers = ['block5_conv2']
    style_layers = ['block1_conv1',
                    'block2_conv1',
                    'block3_conv1',
                    'block4_conv1',
                    'block5_conv1']
    content_model = Model(inputs=vgg.input, outputs=vgg.get_layer(content_layers[0]).output)
    style_model = [Model(inputs=vgg.input, outputs=vgg.get_layer(layer).output) for layer in style_layers]
    return content_model, style_model

def get_feature_representations(model, content_path):
    content_image = load_and_process_img(content_path)
    content_features = model(content_image)
    return content_features

def compute_loss(content_features, generated_features):
    loss = tf.reduce_mean(tf.square(content_features - generated_features))
    return loss

def neural_style_transfer(content_path, broken_path, iterations=1000):
    content_model, style_models = get_model()
    content_features = get_feature_representations(content_model, content_path)
    generated_image = tf.Variable(load_and_process_img(broken_path), dtype=tf.float32)

    opt = tf.optimizers.Adam(learning_rate=5.0)

    for i in range(iterations):
        with tf.GradientTape() as tape:
            generated_features = content_model(generated_image)
            content_loss = compute_loss(content_features, generated_features)
        grad = tape.gradient(content_loss, generated_image)
        opt.apply_gradients([(grad, generated_image)])
        if i % 100 == 0:
            print(f"Iteration {i}, Loss: {content_loss.numpy()}")

    final_img = deprocess_img(generated_image.numpy())
    return final_img

# Paths to images
content_image_path = 'path_to_unbroken_image.png'
broken_image_path = 'path_to_broken_image.png'
output_image_path = 'path_to_fixed_image.png'

# Perform Neural Style Transfer for inpainting
fixed_image = neural_style_transfer(content_image_path, broken_image_path)
cv2.imwrite(output_image_path, fixed_image)
cv2.imshow('Fixed Image', fixed_image)
cv2.waitKey(0)
cv2.destroyAllWindows()
